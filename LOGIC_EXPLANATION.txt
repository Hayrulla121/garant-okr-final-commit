================================================================================
                    OKR PERFORMANCE TRACKER - LOGIC EXPLANATION
================================================================================

This document explains how the OKR Performance Tracker calculates scores and
evaluates performance in simple terms.

================================================================================
1. SCORE SCALE (3.0 to 5.0)
================================================================================

All Key Results (KRs) are scored on a scale from 3.0 to 5.0:

    Score Range     Performance Level     Color
    -----------     -----------------     -----
    5.00            Exceptional          Dark Green
    4.75 - 4.99     Very Good            Green
    4.50 - 4.74     Good                 Light Green
    4.25 - 4.49     Meets Expectations   Orange
    3.00 - 4.24     Below Expectations   Red

The score represents how well you're performing against your targets.


================================================================================
2. THREE TYPES OF METRICS
================================================================================

The system supports three types of Key Results:

A) HIGHER IS BETTER (â†‘)
   - Used when bigger numbers mean better performance
   - Examples: Revenue (%), Customer Satisfaction (%), Projects Completed (#)

B) LOWER IS BETTER (â†“)
   - Used when smaller numbers mean better performance
   - Examples: Bug Count, Response Time (seconds), Error Rate (%)

C) QUALITATIVE (ðŸ“Š)
   - Used for subjective assessments using letter grades
   - Grades: A, B, C, D, E


================================================================================
3. HOW SCORING WORKS - HIGHER IS BETTER (â†‘)
================================================================================

When you set up a KR with "Higher is Better", you define 5 threshold values:

Example: Code Quality Percentage
    - Below:        0%   (Minimum acceptable)
    - Meets:       60%   (Meets expectations)
    - Good:        75%   (Good performance)
    - Very Good:   90%   (Very good performance)
    - Exceptional: 100%  (Perfect/Exceptional)

HOW IT CALCULATES THE SCORE:

Step 1: Compare your actual value to the thresholds
Step 2: Find which range your value falls into
Step 3: Calculate a proportional score within that range

EXAMPLES:

If your actual value is 100% (reached Exceptional threshold):
    â†’ Score = 5.00 (Exceptional)

If your actual value is 92% (between Very Good and Exceptional):
    â†’ Falls in range 90% to 100%
    â†’ Position: 92% is 2/10 = 20% of the way from 90% to 100%
    â†’ Score = 4.75 + (0.20 Ã— 0.24) = 4.79 (Very Good)

If your actual value is 70% (between Meets and Good):
    â†’ Falls in range 60% to 75%
    â†’ Position: 70% is 10/15 = 67% of the way from 60% to 75%
    â†’ Score = 4.25 + (0.67 Ã— 0.24) = 4.41 (Meets)

If your actual value is 50% (below Meets threshold):
    â†’ Falls in range 0% to 60%
    â†’ Position: 50% is 50/60 = 83% of the way from 0% to 60%
    â†’ Score = 3.00 + (0.83 Ã— 1.24) = 4.03 (Below)

If your actual value is below 0%:
    â†’ Score = 3.00 (Below - minimum score)


================================================================================
4. HOW SCORING WORKS - LOWER IS BETTER (â†“)
================================================================================

When you set up a KR with "Lower is Better", you define 5 threshold values:

Example: Bug Count
    - Below:       10 bugs (Maximum acceptable)
    - Meets:        7 bugs (Meets expectations)
    - Good:         5 bugs (Good performance)
    - Very Good:    2 bugs (Very good performance)
    - Exceptional:  0 bugs (Perfect/No bugs)

HOW IT CALCULATES THE SCORE:

The logic is REVERSED compared to "Higher is Better":
- Lower values = Higher scores
- Higher values = Lower scores

EXAMPLES:

If your actual value is 0 bugs (reached Exceptional threshold):
    â†’ Score = 5.00 (Exceptional)

If your actual value is 1 bug (between Exceptional and Very Good):
    â†’ Falls in range 0 to 2 bugs
    â†’ Position: 1 bug is 50% away from exceptional (0)
    â†’ Score = 4.75 + (0.50 Ã— 0.24) = 4.87 (Very Good)

If your actual value is 6 bugs (between Good and Meets):
    â†’ Falls in range 5 to 7 bugs
    â†’ Position: 6 bugs is 50% away from good (5)
    â†’ Score = 4.25 + (0.50 Ã— 0.24) = 4.37 (Meets)

If your actual value is 12 bugs (above Below threshold):
    â†’ Score = 3.00 (Below - minimum score)


================================================================================
5. HOW SCORING WORKS - QUALITATIVE GRADES (ðŸ“Š)
================================================================================

For qualitative assessments, you simply assign a letter grade:

    Grade    Score    Performance Level
    -----    -----    -----------------
      A      5.00     Exceptional
      B      4.75     Very Good
      C      4.50     Good
      D      4.25     Meets Expectations
      E      3.00     Below Expectations

No thresholds are needed - just pick the grade that best represents performance.


================================================================================
6. CALCULATING OBJECTIVE SCORES
================================================================================

Each Objective contains multiple Key Results. The Objective score is calculated
as a SIMPLE AVERAGE of all its Key Results:

    Objective Score = (KR1 Score + KR2 Score + KR3 Score + ...) / Number of KRs

EXAMPLE:

Objective: "Improve Code Quality"
    KR1: Code in Time       â†’ Actual: 80%  â†’ Score: 4.58
    KR2: Engagement         â†’ Actual: 100% â†’ Score: 5.00
    KR3: Code with Bugs     â†’ Actual: 3%   â†’ Score: 4.62

Objective Score = (4.58 + 5.00 + 4.62) / 3 = 4.73 (Very Good)


================================================================================
7. CALCULATING DEPARTMENT SCORES
================================================================================

Each Department contains multiple Objectives. The Department score is calculated
as a WEIGHTED AVERAGE of all its Objectives:

    Department Score = (Obj1_Score Ã— Obj1_Weight + Obj2_Score Ã— Obj2_Weight + ...)
                       / Total Weight

You can assign different weights to objectives (e.g., 20%, 30%, 50%) to
indicate their relative importance.

EXAMPLE:

Department: "IT"
    Objective 1: "Code Quality"    â†’ Score: 4.73, Weight: 20%
    Objective 2: "Frontend"        â†’ Score: 4.85, Weight: 30%
    Objective 3: "Backend"         â†’ Score: 4.90, Weight: 50%

Department Score = (4.73 Ã— 20 + 4.85 Ã— 30 + 4.90 Ã— 50) / 100
                 = (94.6 + 145.5 + 245.0) / 100
                 = 485.1 / 100
                 = 4.85 (Very Good)

NOTE: If weights don't sum to 100%, the system automatically normalizes them.
      If no weights are set, all objectives are weighted equally.


================================================================================
8. CONVERTING SCORES TO PERCENTAGES
================================================================================

The system can display scores as percentages using this formula:

    Percentage = ((Score - 3.0) / 2.0) Ã— 100%

This converts the 3.0-5.0 scale to a 0-100% scale:

    Score    Percentage    Performance Level
    -----    ----------    -----------------
    5.00     100.0%        Exceptional
    4.75      87.5%        Very Good
    4.50      75.0%        Good
    4.25      62.5%        Meets Expectations
    4.00      50.0%        Below Expectations
    3.50      25.0%        Below Expectations
    3.00       0.0%        Below Expectations


================================================================================
9. KEY POINTS TO REMEMBER
================================================================================

1. All scores range from 3.0 (worst) to 5.0 (best)

2. For "Higher is Better": Actual value >= threshold = better score

3. For "Lower is Better": Actual value <= threshold = better score

4. Scores are calculated proportionally within threshold ranges, not just
   at the threshold boundaries

5. Objective scores = Simple average of all Key Results (equal weight)

6. Department scores = Weighted average of all Objectives (can set weights)

7. The system handles edge cases:
   - Values beyond thresholds are capped at min (3.0) or max (5.0)
   - Missing or null values default to 0 and score as 3.0
   - If weights don't sum to 100%, they're automatically normalized

8. The score ranges create clear performance bands:
   - 5.00:       Exceptional (hitting all targets perfectly)
   - 4.75-4.99:  Very Good (exceeding most expectations)
   - 4.50-4.74:  Good (performing well)
   - 4.25-4.49:  Meets (acceptable performance)
   - 3.00-4.24:  Below (needs improvement)


================================================================================
10. VISUAL REPRESENTATION
================================================================================

The system displays scores using:

1. GAUGE CHARTS
   - Semi-circular gauge from 3 to 5
   - Color-coded bands showing performance levels
   - Needle points to your current score

2. COLOR CODING
   - Dark Green (#1e7b34):  Exceptional (5.00)
   - Green (#28a745):       Very Good (4.75-4.99)
   - Light Green (#5cb85c): Good (4.50-4.74)
   - Orange (#f0ad4e):      Meets (4.25-4.49)
   - Red (#d9534f):         Below (3.00-4.24)

3. NUMERIC DISPLAY
   - Shows exact score (e.g., 4.73)
   - Shows percentage equivalent (e.g., 86.5%)
   - Shows performance level text (e.g., "Very Good")


================================================================================
END OF DOCUMENT
================================================================================
